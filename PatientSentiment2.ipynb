{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X8_Rn4QVaP5_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train= pd.read_csv(\"C:/Users/anujq/OneDrive/Documents/Dissertations/HealthCare_analysis/Dataset/train_data.csv\")\n",
        "test= pd.read_csv(\"C:/Users/anujq/OneDrive/Documents/Dissertations/HealthCare_analysis/Dataset/test_data.csv\")\n",
        "\n",
        "import numpy as np\n",
        "df_train = pd.concat([train, test])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install keras==2.13.1\n",
        "#!pip install tensorflow==2.8.0\n",
        "#!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: click in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.7.24-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
            "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
            "     -------------------------------------- 41.5/41.5 kB 680.6 kB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.2/1.5 MB 3.5 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.5/1.5 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 0.8/1.5 MB 6.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.2/1.5 MB 6.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.5/1.5 MB 6.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 6.4 MB/s eta 0:00:00\n",
            "Downloading regex-2024.7.24-cp311-cp311-win_amd64.whl (269 kB)\n",
            "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
            "   ------------------------------------ --- 245.8/269.7 kB 7.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 269.7/269.7 kB 5.5 MB/s eta 0:00:00\n",
            "Installing collected packages: regex, nltk\n",
            "Successfully installed nltk-3.8.1 regex-2024.7.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\anujq\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuzI_UZVaP33",
        "outputId": "8cf74a4f-fc94-4eb3-ba6f-5669ded5f537"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\anujq\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\anujq\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting textblob\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (2024.7.24)\n",
            "Requirement already satisfied: tqdm in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.8->textblob) (4.66.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\anujq\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
            "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
            "    --------------------------------------- 10.2/626.3 kB ? eta -:--:--\n",
            "   ----- ---------------------------------- 92.2/626.3 kB 1.3 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 327.7/626.3 kB 3.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 573.4/626.3 kB 3.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 626.3/626.3 kB 3.6 MB/s eta 0:00:00\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.18.0.post0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: C:\\Users\\anujq\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "G3eLHTS_aP2A"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#Pre-Processing the text\n",
        "def cleaning(df, stop_words):\n",
        "    df_train['Review'] = df_train['FFT answer'].apply(lambda x: ' '.join(x.lower() for x in str(x).split()))\n",
        "    # Replacing the digits/numbers\n",
        "    df['Review'] = df['Review'].str.replace('d', '')\n",
        "    # Removing stop words\n",
        "    df['Review'] = df['Review'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
        "    # Lemmatization\n",
        "    df['Review'] = df['Review'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
        "    return df\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "data_cleaned = cleaning(df_train, stop_words)\n",
        "\n",
        "#Generating Embeddings using tokenizer\n",
        "tokenizer = Tokenizer(num_words=100, split=' ')\n",
        "tokenizer.fit_on_texts(data_cleaned['Review'].values)\n",
        "X = tokenizer.texts_to_sequences(data_cleaned['Review'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "#X= tf.keras.utils.normalize(X, axis=-1, order=2)\n",
        "\n",
        "# one hot encoding on target\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "Y= df_train[\"Comment sentiment\"].values\n",
        "Y= enc.fit_transform(Y.reshape(-1,1)).toarray()\n",
        "\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 3],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 2],\n",
              "       [0, 0, 0, ..., 0, 0, 2],\n",
              "       [0, 0, 0, ..., 0, 0, 2]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqlYAmmybJ0y",
        "outputId": "988514cc-f3ce-4b25-e2fd-99a50e330404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etfdVhELaPz_",
        "outputId": "83395a73-4e9a-48af-d657-7dd9f0ca671c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 83, 160)           16000     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 83, 160)           0         \n",
            "                                                                 \n",
            " spatial_dropout1d_4 (Spati  (None, 83, 160)           0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 512)               1378304   \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1567174 (5.98 MB)\n",
            "Trainable params: 1567174 (5.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "  4/188 [..............................] - ETA: 2:53 - loss: 1.7358 - accuracy: 0.2578 - f1_score: 0.1189"
          ]
        }
      ],
      "source": [
        "#Model Building\n",
        "import keras\n",
        "from keras import optimizers\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 160, input_length = X.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(512, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(256, activation='LeakyReLU'))\n",
        "model.add(Dense(128, activation='LeakyReLU'))\n",
        "model.add(Dense(64, activation='LeakyReLU'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "adam = optimizers.Adam(lr=0.05)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer=adam, metrics = ['accuracy',keras.metrics.F1Score()])\n",
        "print(model.summary())\n",
        "\n",
        "#Model Training\n",
        "history=model.fit(X_train, Y_train, epochs = 50, batch_size=32, verbose =1,validation_split=0.1)\n",
        "\n",
        "#Model Testing\n",
        "score, acc, f1_score = model.evaluate(X_test,Y_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"loss:\",score)\n",
        "print(\"accuracy\",acc)\n",
        "print(\"f1_score\",f1_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsKwbtt7aPyX"
      },
      "outputs": [],
      "source": [
        "#model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1RxWb0TaPtv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0YzmQe9aPrI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
